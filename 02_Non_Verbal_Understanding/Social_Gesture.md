# SocialGesture: Delving into Multi-person Gesture Understanding

**[Paper Info]** CVPR 2025

## 1. Motivation
ê¸°ì¡´ ì œìŠ¤ì²˜ ì¸ì‹ ë°ì´í„°ì…‹ë“¤ì€ ëŒ€ë¶€ë¶„ **"í•œ ì‚¬ëžŒì´ ì¹´ë©”ë¼ë¥¼ ë³´ê³  í•˜ëŠ”(One-person)"** í˜•íƒœì˜€ìŠµë‹ˆë‹¤.
í•˜ì§€ë§Œ ì‹¤ì œ ì‚¬íšŒì  ìƒí˜¸ìž‘ìš©ì€ ì—¬ëŸ¬ ì‚¬ëžŒì´ ì„žì—¬ ìžˆëŠ” í™˜ê²½ì—ì„œ ë°œìƒí•©ë‹ˆë‹¤.

### ðŸ“‰ ê¸°ì¡´ ë°ì´í„°ì…‹ì˜ í•œê³„
* **NVGesture / EgoGesture:** ë…ì‚¬ì§„ ìœ„ì£¼, ìƒí˜¸ìž‘ìš© ë¶€ìž¬.
* **SocialGesture (Ours):** ë‹¤ìžê°„ ìƒí˜¸ìž‘ìš©, ì œìŠ¤ì²˜ì˜ **ì£¼ì²´(Subject)**ì™€ **ëŒ€ìƒ(Target)**ì´ ì¡´ìž¬í•¨.

## 2. SocialGesture Benchmark
ìƒˆë¡­ê²Œ êµ¬ì¶•ëœ ë°ì´í„°ì…‹ì€ ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ì§•ì„ ê°€ì§‘ë‹ˆë‹¤.

| Feature | SocialGesture (Ours) | Existing Datasets |
| :--- | :--- | :--- |
| **Environment** | Multi-person (ë‹¤ìžê°„) | Single-person (ê°œì¸) |
| **Interaction** | Subject â†” Target | Subject Only |
| **Gesture Types** | Pointing, Showing, Giving, Reaching | Generic Gestures |
| **Annotation** | Bounding Box + Relationship | Label Only |

## 3. Tasks Breakdown
ëª¨ë¸ì´ í•´ê²°í•´ì•¼ í•  3ë‹¨ê³„ ê³¼ì œìž…ë‹ˆë‹¤.

1.  **Gesture Detection:** í˜„ìž¬ ìž¥ë©´ì—ì„œ ì‚¬íšŒì  ì œìŠ¤ì²˜ê°€ ë°œìƒí–ˆëŠ”ê°€? (Yes/No)
2.  **Gesture Type Classification:** ì–´ë–¤ ì¢…ë¥˜ì˜ ì œìŠ¤ì²˜ì¸ê°€? (Pointing / Showing / Giving / Reaching)
3.  **Gesture Localization:**
    * **Subject:** ëˆ„ê°€ ì œìŠ¤ì²˜ë¥¼ í–ˆëŠ”ê°€? (BBox)
    * **Target:** ëˆ„êµ¬/ë¬´ì—‡ì„ í–¥í–ˆëŠ”ê°€? (BBox)

## 4. Annotation Pipeline
GPT-4oì™€ ì¸ê°„ ê²€ìˆ˜ìžë¥¼ ê²°í•©í•œ íš¨ìœ¨ì ì¸ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤.
* **Video Input** -> **GPT-4o Generation** -> **Three-person Consensus (ì‚¬ëžŒ ê²€ìˆ˜)** -> **Final Label**